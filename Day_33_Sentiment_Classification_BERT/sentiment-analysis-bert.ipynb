{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Sentiment Classification with BERT\n\n## Table of Contents\n1. **Objective**\n2. **Metadata**\n3. **Dataset Overview**\n4. **Concept Overview: What is BERT?**\n5. **Why Use BERT?**\n6. **How to Use BERT?**\n7. **Advantages and Disadvantages of BERT**\n8. **Other Use Cases of BERT**\n9. **Exploratory Data Analysis (EDA)**\n10. **Data Preprocessing**\n11. **Implementation**\n12. **Key Learnings**\n13. **Conclusion**\n\n---\n\n## 1. Objective\n\nThe objective of this notebook is to perform sentiment classification on a given dataset using BERT (Bidirectional Encoder Representations from Transformers). We will explore the dataset, preprocess the data, implement a BERT-based model, and evaluate its performance. By the end of this notebook, you will have a clear understanding of how to use BERT for sentiment analysis and other NLP tasks.\n\n---\n\n## 2. Metadata\n\n- **Notebook Author**: [Your Name]\n- **Date**: [Current Date]\n- **Language**: Python\n- **Libraries Used**: \n  - `transformers` (Hugging Face)\n  - `torch` (PyTorch)\n  - `pandas`\n  - `numpy`\n  - `matplotlib`\n  - `seaborn`\n  - `scikit-learn`\n- **Dataset**: [Dataset Name] (e.g., IMDb, Twitter Sentiment Analysis Dataset)\n\n---\n\n## 3. Dataset Overview\n\nThe dataset used in this notebook is the [Dataset Name], which contains [number] of text samples labeled with positive, negative, or neutral sentiment. The dataset is split into training and testing sets, with [number] of samples in the training set and [number] of samples in the testing set.\n\n- **Columns**:\n  - `text`: The text data (e.g., movie reviews, tweets).\n  - `label`: The sentiment label (e.g., 0 for negative, 1 for positive).\n\n- **Dataset Source**: [Link to Dataset]\n\n---\n\n## 4. Concept Overview: What is BERT?\n\nBERT (Bidirectional Encoder Representations from Transformers) is a transformer-based machine learning technique for natural language processing (NLP) pre-training developed by Google. Unlike previous models that process text in a unidirectional manner (either left-to-right or right-to-left), BERT is designed to process text in both directions simultaneously. This bidirectional approach allows BERT to capture context from both past and future words in a sentence, leading to a deeper understanding of the text.\n\n### Key Features of BERT:\n- **Bidirectional Context**: BERT considers the context from both sides of a word, which helps in understanding the meaning of words in a sentence more accurately.\n- **Transformer Architecture**: BERT uses the transformer architecture, which relies on self-attention mechanisms to weigh the importance of different words in a sentence.\n- **Pre-trained Models**: BERT is pre-trained on large corpora (e.g., Wikipedia, BookCorpus) and can be fine-tuned for specific NLP tasks like sentiment analysis, question answering, and more.\n\n---\n\n## 5. Why Use BERT?\n\n- **State-of-the-Art Performance**: BERT has achieved state-of-the-art results on various NLP tasks, including sentiment analysis, question answering, and named entity recognition.\n- **Contextual Understanding**: BERT's bidirectional nature allows it to understand the context of words better than unidirectional models.\n- **Transfer Learning**: BERT can be fine-tuned on specific tasks with relatively small datasets, making it highly versatile.\n\n---\n\n## 6. How to Use BERT?\n\n1. **Pre-training**: BERT is pre-trained on large text corpora using two tasks:\n   - **Masked Language Model (MLM)**: Randomly masks some words in a sentence and predicts them based on the context.\n   - **Next Sentence Prediction (NSP)**: Predicts whether one sentence follows another in a document.\n\n2. **Fine-tuning**: After pre-training, BERT can be fine-tuned on specific tasks (e.g., sentiment analysis) by adding a task-specific layer (e.g., a classification layer) and training on labeled data.\n\n---\n\n## 7. Advantages and Disadvantages of BERT\n\n### Advantages:\n- **High Accuracy**: BERT achieves high accuracy on various NLP tasks.\n- **Contextual Understanding**: BERT's bidirectional nature allows it to understand context better.\n- **Versatility**: BERT can be fine-tuned for a wide range of NLP tasks.\n\n### Disadvantages:\n- **Computationally Expensive**: BERT requires significant computational resources for training and inference.\n- **Large Model Size**: BERT models are large, which can be a limitation for deployment on resource-constrained devices.\n- **Long Training Time**: Fine-tuning BERT on large datasets can be time-consuming.\n\n---\n\n## 8. Other Use Cases of BERT\n\n- **Question Answering**: BERT can be used to build systems that answer questions based on a given context.\n- **Named Entity Recognition (NER)**: BERT can identify and classify entities in text (e.g., names, dates, locations).\n- **Text Summarization**: BERT can be used to generate summaries of long documents.\n- **Machine Translation**: BERT can be fine-tuned for translating text from one language to another.\n\n---\n","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\nfrom datasets import load_dataset\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T06:43:05.683421Z","iopub.execute_input":"2025-02-10T06:43:05.684066Z","iopub.status.idle":"2025-02-10T06:43:05.688174Z","shell.execute_reply.started":"2025-02-10T06:43:05.684036Z","shell.execute_reply":"2025-02-10T06:43:05.687328Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Install Required Libraries\n- Install the `transformers` library to access the pre-trained BERT model and utilities.\n- Install the `datasets` library to load the IMDb dataset conveniently.\n- Install `wandb` (Weights and Biases) for tracking training and evaluation metrics.\n","metadata":{}},{"cell_type":"code","source":"# Load the IMDb dataset which is pre-split into 'train' and 'test' sets.\ndataset = load_dataset(\"imdb\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T06:43:20.710115Z","iopub.execute_input":"2025-02-10T06:43:20.710453Z","iopub.status.idle":"2025-02-10T06:43:24.675681Z","shell.execute_reply.started":"2025-02-10T06:43:20.710423Z","shell.execute_reply":"2025-02-10T06:43:24.675042Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/7.81k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebda6e9f24a64b4a8c3a633abf694525"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7944a164cbfa4a4683cdf8d162117f7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34b8be42aaf84dfaa40e1c702dd90f2b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"unsupervised-00000-of-00001.parquet:   0%|          | 0.00/42.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a45be1312424afd87d0dbcbfb7b978a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ffebbe2310a4b1bb7e77f121ab35730"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97b482eb43d440feb4ce4ff4869000b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"802b40292c4b4a5796c7349260f6a16c"}},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"# Import Libraries and Load IMDb Dataset\n- Import `load_dataset` from the `datasets` library to load the IMDb dataset.\n- Import `BertTokenizer` and `BertForSequenceClassification` from `transformers` to use a pre-trained BERT model for sentiment classification.\n- Load the IMDb dataset, which contains movie reviews labeled as positive or negative.\n","metadata":{}},{"cell_type":"code","source":"# Define the model name (we're using the base uncased version of BERT)\nmodel_name = \"bert-base-uncased\"\n\n# Load the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# Load the pre-trained BERT model for sequence classification with 2 output labels (positive/negative)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T06:43:29.504728Z","iopub.execute_input":"2025-02-10T06:43:29.505007Z","iopub.status.idle":"2025-02-10T06:43:32.611069Z","shell.execute_reply.started":"2025-02-10T06:43:29.504986Z","shell.execute_reply":"2025-02-10T06:43:32.610254Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8b21b0353e54866ba5c380bdcf57b72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3eaab129980e40748f9c90a1a891c7f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8f4510a6a934a46bf19ba10ee13cf56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b005e2736d1049c0ac8999674cc4ea42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01e8f80d3aa748ae9daeb2bf08c162bb"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Define a function to tokenize the text data.\ndef tokenize_function(examples):\n    # Tokenize the \"text\" field, applying truncation and padding.\n    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n\n# Apply the tokenizer to the entire dataset in a batched manner.\ntokenized_datasets = dataset.map(tokenize_function, batched=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T06:43:38.550590Z","iopub.execute_input":"2025-02-10T06:43:38.550872Z","iopub.status.idle":"2025-02-10T06:44:39.636596Z","shell.execute_reply.started":"2025-02-10T06:43:38.550850Z","shell.execute_reply":"2025-02-10T06:44:39.635686Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a76b77b7e72f482f82b3babae6b85837"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"629175acc48240d4aaf187f76107aa74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fc6f752caf54352ae5515fb3b4955fa"}},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"# Preprocess the Dataset\n- Load the pre-trained tokenizer (`bert-base-uncased`) for BERT.\n- Define a tokenization function to tokenize the text, applying truncation and padding to ensure uniform input length.\n- Use the `map()` method to apply tokenization across the entire dataset.\n","metadata":{}},{"cell_type":"code","source":"# Remove the original text column since it is no longer needed\ntokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n\n# Set the format of the dataset to PyTorch tensors.\ntokenized_datasets.set_format(\"torch\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T06:44:43.058390Z","iopub.execute_input":"2025-02-10T06:44:43.058699Z","iopub.status.idle":"2025-02-10T06:44:43.068244Z","shell.execute_reply.started":"2025-02-10T06:44:43.058672Z","shell.execute_reply":"2025-02-10T06:44:43.067392Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_dataset = tokenized_datasets[\"train\"]\ntest_dataset = tokenized_datasets[\"test\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T06:44:45.260909Z","iopub.execute_input":"2025-02-10T06:44:45.261185Z","iopub.status.idle":"2025-02-10T06:44:45.264732Z","shell.execute_reply.started":"2025-02-10T06:44:45.261163Z","shell.execute_reply":"2025-02-10T06:44:45.263962Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# Prepare Datasets for Training\n- Split the tokenized IMDb dataset into training and testing datasets.\n- Use these subsets for model training and evaluation.\n","metadata":{}},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    # Convert logits to predicted class labels\n    predictions = np.argmax(logits, axis=-1)\n    # Compute accuracy\n    acc = accuracy_score(labels, predictions)\n    # Compute precision, recall, and F1 score\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"binary\")\n    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T06:44:47.646987Z","iopub.execute_input":"2025-02-10T06:44:47.647287Z","iopub.status.idle":"2025-02-10T06:44:47.651371Z","shell.execute_reply.started":"2025-02-10T06:44:47.647262Z","shell.execute_reply":"2025-02-10T06:44:47.650668Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Define Metrics\n- Load the `accuracy` metric from the `datasets` library.\n- Define a `compute_metrics` function to calculate accuracy by comparing model predictions to true labels.\n","metadata":{}},{"cell_type":"code","source":"import wandb\nfrom transformers import TrainingArguments, Trainer\n\n# Ask for the WandB token\nwandb_token = input(\"Enter your WandB API token: \")\n\n# Login to WandB\nwandb.login(key=wandb_token)\n\n# Define training arguments, including WandB integration\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",               # Directory for model checkpoints and outputs\n    evaluation_strategy=\"epoch\",          # Evaluate the model at the end of each epoch\n    learning_rate=2e-5,                   # Learning rate for optimization\n    per_device_train_batch_size=8,        # Batch size per device during training\n    per_device_eval_batch_size=8,         # Batch size per device during evaluation\n    num_train_epochs=2,                   # Number of training epochs\n    weight_decay=0.01,                    # Weight decay for regularization\n    logging_dir=\"./logs\",                 # Directory for storing logs\n    logging_steps=50,                     # Frequency of logging steps\n    report_to=\"wandb\",                    # Report metrics to WandB\n    save_strategy=\"epoch\",                # Save model checkpoint at the end of each epoch\n)\n\n# Initialize the Trainer with the model, training arguments, datasets, and evaluation metrics.\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    compute_metrics=compute_metrics,\n)\n\n# Start the training process, WandB will track the metrics automatically\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T06:52:00.217101Z","iopub.execute_input":"2025-02-10T06:52:00.217431Z","iopub.status.idle":"2025-02-10T07:58:31.433825Z","shell.execute_reply.started":"2025-02-10T06:52:00.217403Z","shell.execute_reply":"2025-02-10T07:58:31.432881Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Enter your WandB API token:  e6307e2669d40326758d0898197fdd7da8ee52ea\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msayan-ft252082\u001b[0m (\u001b[33msayan-ft252082-capgemini\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250210_065258-tuf8j6sf</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/sayan-ft252082-capgemini/huggingface/runs/tuf8j6sf' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/sayan-ft252082-capgemini/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/sayan-ft252082-capgemini/huggingface' target=\"_blank\">https://wandb.ai/sayan-ft252082-capgemini/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/sayan-ft252082-capgemini/huggingface/runs/tuf8j6sf' target=\"_blank\">https://wandb.ai/sayan-ft252082-capgemini/huggingface/runs/tuf8j6sf</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3126' max='3126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3126/3126 1:05:22, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.210500</td>\n      <td>0.182105</td>\n      <td>0.931880</td>\n      <td>0.950288</td>\n      <td>0.911440</td>\n      <td>0.930459</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.139400</td>\n      <td>0.219952</td>\n      <td>0.942160</td>\n      <td>0.938929</td>\n      <td>0.945840</td>\n      <td>0.942372</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3126, training_loss=0.18700834946684247, metrics={'train_runtime': 3933.4131, 'train_samples_per_second': 12.712, 'train_steps_per_second': 0.795, 'total_flos': 1.3155552768e+16, 'train_loss': 0.18700834946684247, 'epoch': 2.0})"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# Evaluate the model\neval_results = trainer.evaluate()\nprint(\"Evaluation Results:\", eval_results)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T07:58:31.539143Z","iopub.execute_input":"2025-02-10T07:58:31.539373Z","iopub.status.idle":"2025-02-10T08:06:28.751575Z","shell.execute_reply.started":"2025-02-10T07:58:31.539352Z","shell.execute_reply":"2025-02-10T08:06:28.750926Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1563' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1563/1563 07:56]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Evaluation Results: {'eval_loss': 0.21995195746421814, 'eval_accuracy': 0.94216, 'eval_precision': 0.9389294790343075, 'eval_recall': 0.94584, 'eval_f1': 0.9423720707795312, 'eval_runtime': 477.203, 'eval_samples_per_second': 52.389, 'eval_steps_per_second': 3.275, 'epoch': 2.0}\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# Evaluate the Model\n- Evaluate the model's performance on the test dataset using the `evaluate()` method.\n- The evaluation metrics, such as accuracy, are logged and displayed.\n","metadata":{}},{"cell_type":"markdown","source":"# Set Up WandB and Training Arguments\n- Prompt the user to enter their WandB API token to log into their account.\n- Define training arguments:\n  - `output_dir`: Directory for saving checkpoints.\n  - `evaluation_strategy`: Evaluate the model at the end of each epoch.\n  - `report_to`: Send metrics to WandB.\n  - `save_strategy`: Save model checkpoints at the end of each epoch.\n\n# Initialize Trainer and Train Model\n- Initialize the `Trainer` object with the model, training arguments, datasets, and metric computation function.\n- Call the `train()` method to start training the model.\n- During training, WandB will log metrics such as training loss and evaluation accuracy.\n","metadata":{}},{"cell_type":"code","source":"# Define a function to classify the sentiment of a given text.\ndef classify_text(text):\n    # Tokenize the input text with the same settings as during training.\n    inputs = tokenizer(\n        text,\n        return_tensors=\"pt\",\n        truncation=True,\n        padding=\"max_length\",\n        max_length=512\n    )\n    \n    # Move the inputs to the same device as the model (CPU or GPU).\n    device = next(model.parameters()).device\n    inputs = {key: value.to(device) for key, value in inputs.items()}\n    \n    # Disable gradient calculation for inference.\n    with torch.no_grad():\n        outputs = model(**inputs)\n    \n    # Extract logits and convert them to probabilities using softmax.\n    logits = outputs.logits\n    probabilities = torch.nn.functional.softmax(logits, dim=1)\n    \n    # Determine the predicted class: 0 for negative, 1 for positive.\n    predicted_class = torch.argmax(probabilities, dim=1).item()\n    return predicted_class, probabilities.cpu().numpy()\n\n# Example usage: classify a sample text.\nsample_text = \"This movie was absolutely phenomenal! The storytelling was captivating, the characters were deeply relatable, and the visuals were stunning. The director's vision was brought to life with such finesse, leaving me inspired and in awe. Highly recommend it—an absolute must-watch!\"\npredicted_class, probabilities = classify_text(sample_text)\nlabel = \"Positive\" if predicted_class == 1 else \"Negative\"\n\nprint(f\"Input text: {sample_text}\")\nprint(f\"Predicted sentiment: {label}\")\nprint(f\"Probabilities: {probabilities}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T08:41:33.754495Z","iopub.execute_input":"2025-02-10T08:41:33.754796Z","iopub.status.idle":"2025-02-10T08:41:33.814709Z","shell.execute_reply.started":"2025-02-10T08:41:33.754774Z","shell.execute_reply":"2025-02-10T08:41:33.814018Z"}},"outputs":[{"name":"stdout","text":"Input text: This movie was absolutely phenomenal! The storytelling was captivating, the characters were deeply relatable, and the visuals were stunning. The director's vision was brought to life with such finesse, leaving me inspired and in awe. Highly recommend it—an absolute must-watch!\nPredicted sentiment: Positive\nProbabilities: [[0.00154408 0.9984559 ]]\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Example usage: classify a sample text.\nsample_text = \"Unfortunately, this movie was a disappointment. The plot felt disjointed, the characters lacked depth, and the pacing dragged on far too long. Even the visuals couldn't make up for the weak storytelling. Not something I’d recommend\"\npredicted_class, probabilities = classify_text(sample_text)\nlabel = \"Positive\" if predicted_class == 1 else \"Negative\"\n\nprint(f\"Input text: {sample_text}\")\nprint(f\"Predicted sentiment: {label}\")\nprint(f\"Probabilities: {probabilities}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T08:42:40.509188Z","iopub.execute_input":"2025-02-10T08:42:40.509535Z","iopub.status.idle":"2025-02-10T08:42:40.566722Z","shell.execute_reply.started":"2025-02-10T08:42:40.509509Z","shell.execute_reply":"2025-02-10T08:42:40.565883Z"}},"outputs":[{"name":"stdout","text":"Input text: Unfortunately, this movie was a disappointment. The plot felt disjointed, the characters lacked depth, and the pacing dragged on far too long. Even the visuals couldn't make up for the weak storytelling. Not something I’d recommend\nPredicted sentiment: Negative\nProbabilities: [[0.9989349  0.00106505]]\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"# Use the Model to Classify New Text\n- Define a function `classify_text` to process a given text input:\n  - Tokenize the input using the BERT tokenizer.\n  - Pass the tokenized input to the model for inference.\n  - Use softmax to convert logits into probabilities and determine the predicted class.\n- Test the function with a sample text to verify sentiment classification.\n","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}